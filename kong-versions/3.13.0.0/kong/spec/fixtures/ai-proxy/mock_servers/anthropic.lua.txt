server {
    server_name anthropic;
    listen %s;

    default_type 'application/json';


    location = "/llm/v1/chat/good" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        local token = ngx.req.get_headers()["x-api-key"]
        if token == "anthropic-key" then
          ngx.req.read_body()
          local body, err = ngx.req.get_body_data()
          body, err = json.decode(body)

          if err or (not body.messages) then
            ngx.status = 400
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_request.json"))
          else
            ngx.status = 200
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/good.json"))
          end
        else
          ngx.status = 401
          ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/unauthorized.json"))
        end
      }
    }

    location = "/llm/v1/chat/bad_upstream_response" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        local token = ngx.req.get_headers()["x-api-key"]
        if token == "anthropic-key" then
          ngx.req.read_body()
          local body, err = ngx.req.get_body_data()
          body, err = json.decode(body)

          if err or (not body.messages) then
            ngx.status = 400
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_request.json"))
          else
            ngx.status = 200
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_upstream_response.json"))
          end
        else
          ngx.status = 401
          ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/unauthorized.json"))
        end
      }
    }

    location = "/llm/v1/chat/no_usage_upstream_response" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        local token = ngx.req.get_headers()["x-api-key"]
        if token == "anthropic-key" then
          ngx.req.read_body()
          local body, err = ngx.req.get_body_data()
          body, err = json.decode(body)

          if err or (not body.messages) then
            ngx.status = 400
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_request.json"))
          else
            ngx.status = 200
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/no_usage_response.json"))
          end
        else
          ngx.status = 401
          ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/unauthorized.json"))
        end
      }
    }

    location = "/llm/v1/chat/malformed_usage_upstream_response" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        local token = ngx.req.get_headers()["x-api-key"]
        if token == "anthropic-key" then
          ngx.req.read_body()
          local body, err = ngx.req.get_body_data()
          body, err = json.decode(body)

          if err or (not body.messages) then
            ngx.status = 400
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_request.json"))
          else
            ngx.status = 200
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/malformed_usage_response.json"))
          end
        else
          ngx.status = 401
          ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/unauthorized.json"))
        end
      }
    }

    location = "/llm/v1/chat/bad_request" {
      content_by_lua_block {
        local pl_file = require "pl.file"

        ngx.status = 400
        ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/bad_request.json"))
      }
    }

    location = "/llm/v1/chat/internal_server_error" {
      content_by_lua_block {
        local pl_file = require "pl.file"

        ngx.status = 500
        ngx.header["content-type"] = "text/html"
        ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/internal_server_error.html"))
      }
    }

    location = "/llm/v1/chat/tool_choice" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        ngx.req.read_body()
        local function assert_ok(ok, err)
          if not ok then
            ngx.status = 500
            ngx.say(err)
            ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)
          end
          return ok
        end
        local body = assert_ok(ngx.req.get_body_data())
        body = assert_ok(json.decode(body))
        local tool_choice = body.tool_choice
        ngx.header["tool-choice"] = json.encode(tool_choice)
        ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-chat/responses/good.json"))
      }
    }

    location = "/llm/v1/completions/good" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")

        local token = ngx.req.get_headers()["x-api-key"]
        if token == "anthropic-key" then
          ngx.req.read_body()
          local body, err = ngx.req.get_body_data()
          body, err = json.decode(body)

          if err or (not body.prompt) then
            ngx.status = 400
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-completions/responses/bad_request.json"))
          else
            ngx.status = 200
            ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-completions/responses/good.json"))
          end
        else
          ngx.status = 401
          ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-completions/responses/unauthorized.json"))
        end
      }
    }

    location = "/llm/v1/completions/bad_request" {
      content_by_lua_block {
        local pl_file = require "pl.file"

        ngx.status = 400
        ngx.print(pl_file.read("spec/fixtures/ai-proxy/anthropic/llm-v1-completions/responses/bad_request.json"))
      }
    }

    location "/v1/messages/batches" {
      content_by_lua_block {
        local pl_file = require "pl.file"
        local json = require("cjson.safe")
        local method = ngx.req.get_method()
        local uri = ngx.var.uri

        ngx.status = 200
        local path
        if method == "GET" then
          -- get batches job
          if uri:match('/batches/([^/]+)$') then
            -- get batches job returns the same with creation
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/created_good.json"

          -- get results
          elseif uri:match('/batches/([^/]+)/results$') then
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/get_results_good.jsonl"

          -- list
          elseif uri:match('/batches$') then
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/list_good.json"

          else
            ngx.status = 400
          end

        elseif method == "POST" then
          -- create
          if uri:match('/batches$') then
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/created_good.json"

          elseif uri:match('/batches/([^/]+)/cancel$') then
            -- cancel
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/cancel_good.json"

          else ngx.status = 400
          end

        elseif method == "DELETE" then
          -- delete
          if uri:match('/batches/([^/]+)$') then
            path = "spec/fixtures/ai-proxy/anthropic/llm-v1-batches/created_good.json"

          else ngx.status = 400
          end
        end

        if path then
          ngx.print(pl_file.read(path))
        end
      }
    }

}
